{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b079047-0056-49e2-a31f-db68c1144c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Surbhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import random\n",
    "\n",
    "# Initialize Sentiment Analyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "driver = webdriver.Edge()  \n",
    "driver.get(\"https://x.com/login\")  # Open Twitter login page\n",
    "time.sleep(5)  # Wait for page to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b38eaf-333b-472f-89ad-15e1c752eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()  # Load .env variables\n",
    "\n",
    "username = os.getenv(\"TWITTER_USERNAME\")\n",
    "password = os.getenv(\"TWITTER_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc503101-199c-46a1-90cb-1a1154da4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter username\n",
    "username_input = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//input[@name=\"text\"]'))\n",
    ")\n",
    "username_input.send_keys(username)\n",
    "username_input.send_keys(Keys.RETURN)\n",
    "time.sleep(3)\n",
    "\n",
    "# Wait and enter password\n",
    "password_input = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//input[@name=\"password\"]'))\n",
    ")\n",
    "password_input.send_keys(password)\n",
    "password_input.send_keys(Keys.RETURN)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16db9989-dafe-4c56-80b1-7532b3c06e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Searching for tweets about Samsung...\n",
      "📝 19 tweets loaded for Samsung...\n",
      "📝 32 tweets loaded for Samsung...\n",
      "📝 49 tweets loaded for Samsung...\n",
      "📝 59 tweets loaded for Samsung...\n",
      "📝 77 tweets loaded for Samsung...\n",
      "📝 90 tweets loaded for Samsung...\n",
      "📝 100 tweets loaded for Samsung...\n",
      "🔄 Searching for tweets about iPhone...\n",
      "📝 13 tweets loaded for iPhone...\n",
      "📝 27 tweets loaded for iPhone...\n",
      "📝 36 tweets loaded for iPhone...\n",
      "📝 47 tweets loaded for iPhone...\n",
      "📝 55 tweets loaded for iPhone...\n",
      "📝 67 tweets loaded for iPhone...\n",
      "📝 79 tweets loaded for iPhone...\n",
      "📝 89 tweets loaded for iPhone...\n",
      "📝 100 tweets loaded for iPhone...\n"
     ]
    }
   ],
   "source": [
    "# Helper: Extract location by visiting profile\n",
    "def get_user_location(username):\n",
    "    try:\n",
    "        profile_url = f\"https://x.com/{username}\"\n",
    "        driver.execute_script(\"window.open('');\")\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        driver.get(profile_url)\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "\n",
    "        # Try getting location by scanning the profile's bio section\n",
    "        spans = driver.find_elements(By.XPATH, '//div[@data-testid=\"UserProfileHeader_Items\"]/span')\n",
    "        for span in spans:\n",
    "            txt = span.text.strip()\n",
    "            if txt and not txt.startswith(\"@\") and not txt.startswith(\"Joined\"):\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                return txt\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        return \"Unknown\"\n",
    "    except:\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Setup\n",
    "brands = [\"Samsung\", \"iPhone\"]\n",
    "all_tweets = []\n",
    "TWEETS_PER_BRAND = 100  # Reduce for testing, can increase\n",
    "all_hashtags = []\n",
    "all_keywords = []\n",
    "visited_users = {}\n",
    "\n",
    "for brand in brands:\n",
    "    print(f\"🔄 Searching for tweets about {brand}...\")\n",
    "\n",
    "    search_url = f\"https://x.com/search?q={brand}&src=typed_query&f=live\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    tweet_data = []\n",
    "    scroll_attempts = 0\n",
    "    max_scrolls = 30\n",
    "\n",
    "    while len(tweet_data) < TWEETS_PER_BRAND and scroll_attempts < max_scrolls:\n",
    "        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]')\n",
    "\n",
    "        for tweet in tweets:\n",
    "            if len(tweet_data) >= TWEETS_PER_BRAND:\n",
    "                break\n",
    "\n",
    "            tweet_info = {\"Brand\": brand}\n",
    "\n",
    "            try:\n",
    "                tweet_text = tweet.find_element(By.XPATH, './/div[@data-testid=\"tweetText\"]').text\n",
    "                tweet_info[\"Tweet\"] = tweet_text\n",
    "            except:\n",
    "                tweet_info[\"Tweet\"] = \"Not Found\"\n",
    "\n",
    "            tweet_info[\"Sentiment Score\"] = sia.polarity_scores(tweet_info[\"Tweet\"])[\"compound\"]\n",
    "            tweet_info[\"Sentiment\"] = (\n",
    "                \"Positive\" if tweet_info[\"Sentiment Score\"] > 0\n",
    "                else \"Negative\" if tweet_info[\"Sentiment Score\"] < 0\n",
    "                else \"Neutral\"\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                likes = tweet.find_element(By.XPATH, './/button[@data-testid=\"like\"]//span').text\n",
    "                tweet_info[\"Likes\"] = likes.replace(\"K\", \"000\").replace(\"M\", \"000000\")\n",
    "            except:\n",
    "                tweet_info[\"Likes\"] = \"0\"\n",
    "\n",
    "            try:\n",
    "                retweets = tweet.find_element(By.XPATH, './/button[@data-testid=\"retweet\"]//span').text\n",
    "                tweet_info[\"Retweets\"] = retweets.replace(\"K\", \"000\").replace(\"M\", \"000000\")\n",
    "            except:\n",
    "                tweet_info[\"Retweets\"] = \"0\"\n",
    "\n",
    "            try:\n",
    "                tweet_info[\"Time\"] = tweet.find_element(By.XPATH, './/time').get_attribute(\"datetime\")\n",
    "            except:\n",
    "                tweet_info[\"Time\"] = \"Not Available\"\n",
    "\n",
    "            hashtags = [word for word in tweet_info[\"Tweet\"].split() if word.startswith(\"#\")]\n",
    "            mentions = [word for word in tweet_info[\"Tweet\"].split() if word.startswith(\"@\")]\n",
    "            tweet_info[\"Hashtags\"] = \", \".join(hashtags)\n",
    "            tweet_info[\"Mentions\"] = \", \".join(mentions)\n",
    "            all_hashtags.extend(hashtags)\n",
    "            all_keywords.extend(tweet_info[\"Tweet\"].split())\n",
    "\n",
    "            try:\n",
    "                handle_elem = tweet.find_element(By.XPATH, './/a[contains(@href, \"/status/\")]')\n",
    "                handle_url = handle_elem.get_attribute(\"href\")\n",
    "                username = handle_url.split(\"/\")[3]  # https://x.com/{username}/status/...\n",
    "                tweet_info[\"Username\"] = username\n",
    "            except:\n",
    "                tweet_info[\"Username\"] = \"Unknown\"\n",
    "                username = \"Unknown\"\n",
    "\n",
    "            try:\n",
    "                img = tweet.find_element(By.XPATH, './/img[contains(@alt, \"Image\")]')\n",
    "                tweet_info[\"Profile Image\"] = img.get_attribute(\"src\")\n",
    "            except:\n",
    "                tweet_info[\"Profile Image\"] = \"Not Available\"\n",
    "\n",
    "            try:\n",
    "                media = tweet.find_element(By.XPATH, './/img[contains(@src, \"twimg\")]')\n",
    "                tweet_info[\"Media\"] = media.get_attribute(\"src\")\n",
    "            except:\n",
    "                tweet_info[\"Media\"] = \"None\"\n",
    "\n",
    "            try:\n",
    "                device_element = tweet.find_elements(By.XPATH, './/span[contains(@class, \"css-901oao\")]')\n",
    "                for el in device_element:\n",
    "                    text = el.text\n",
    "                    if \"Twitter for\" in text:\n",
    "                        tweet_info[\"Device\"] = text\n",
    "                        break\n",
    "                else:\n",
    "                    tweet_info[\"Device\"] = \"Unknown\"\n",
    "            except:\n",
    "                tweet_info[\"Device\"] = \"Unknown\"\n",
    "\n",
    "            # Get location from profile only if username is known\n",
    "            if username != \"Unknown\":\n",
    "                if username in visited_users:\n",
    "                    tweet_info[\"Location\"] = visited_users[username]\n",
    "                else:\n",
    "                    loc = get_user_location(username)\n",
    "                    visited_users[username] = loc\n",
    "                    tweet_info[\"Location\"] = loc\n",
    "            else:\n",
    "                tweet_info[\"Location\"] = \"Unknown\"\n",
    "\n",
    "            tweet_data.append(tweet_info)\n",
    "\n",
    "        print(f\"📝 {len(tweet_data)} tweets loaded for {brand}...\")\n",
    "        scroll_attempts += 1\n",
    "\n",
    "    all_tweets.extend(tweet_data)\n",
    "\n",
    "# Save data\n",
    "df = pd.DataFrame(all_tweets)\n",
    "df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n",
    "df['Date'] = df['Time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cc241c1-6f3b-43ce-a9aa-15977a18cf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Time</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Username</th>\n",
       "      <th>Profile Image</th>\n",
       "      <th>Media</th>\n",
       "      <th>Device</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Je m'en fous des iPhones j'ai toujours eu des ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:07:54+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Oscar68686</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/190779772...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Hérault, Languedoc-Roussillon</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Mlm ini juga aku jabanin,</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>Negative</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:07:53+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RcSamsung1</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/190629084...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>진만누나 믿어요</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:07:52+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PuDdInG5_</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/190683589...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Samsungのリングも見てみたら5〜15号\\n誰のどの指に付けること前提なんだろう？大人が...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:07:48+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kenji_yogi</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/166714932...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>St john's co-cathedral</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Aku pengguna samsung dari tahun 2018, hp perta...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:07:41+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>calonkamumas</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/176090691...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>di rumah</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>iPhone dreigt onbetaalbaar te worden door Trum...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:11:30+00:00</td>\n",
       "      <td>#telegraafpremium</td>\n",
       "      <td>@Telegraaf</td>\n",
       "      <td>johan1970nl</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/650051636...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Breda, Nederland</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>アメリカ人、もうiPhoneかえんようになるな</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:11:27+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>f1at</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/755025300...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>Oye que cámara tan horrible del iPhone 15 pro ...</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>Negative</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:11:27+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Nellteg1</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/185375689...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>今のうちにiPhone買っとかないと国内も中古品暴騰するんじゃないの\\n転売ヤー歓喜してそう</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:11:26+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kemo3asada51345</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://abs.twimg.com/sticky/default_profile_i...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>só fala mal de iphone quem não tem</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:11:25+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>quellspfc</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/190813881...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                              Tweet  \\\n",
       "0    Samsung  Je m'en fous des iPhones j'ai toujours eu des ...   \n",
       "1    Samsung                         Mlm ini juga aku jabanin,    \n",
       "2    Samsung                                           진만누나 믿어요   \n",
       "3    Samsung  Samsungのリングも見てみたら5〜15号\\n誰のどの指に付けること前提なんだろう？大人が...   \n",
       "4    Samsung  Aku pengguna samsung dari tahun 2018, hp perta...   \n",
       "..       ...                                                ...   \n",
       "195   iPhone  iPhone dreigt onbetaalbaar te worden door Trum...   \n",
       "196   iPhone                            アメリカ人、もうiPhoneかえんようになるな   \n",
       "197   iPhone  Oye que cámara tan horrible del iPhone 15 pro ...   \n",
       "198   iPhone     今のうちにiPhone買っとかないと国内も中古品暴騰するんじゃないの\\n転売ヤー歓喜してそう   \n",
       "199   iPhone                 só fala mal de iphone quem não tem   \n",
       "\n",
       "     Sentiment Score Sentiment Likes Retweets                      Time  \\\n",
       "0             0.0000   Neutral                2025-04-09 11:07:54+00:00   \n",
       "1            -0.3400  Negative                2025-04-09 11:07:53+00:00   \n",
       "2             0.0000   Neutral                2025-04-09 11:07:52+00:00   \n",
       "3             0.0000   Neutral                2025-04-09 11:07:48+00:00   \n",
       "4             0.0000   Neutral                2025-04-09 11:07:41+00:00   \n",
       "..               ...       ...   ...      ...                       ...   \n",
       "195           0.0000   Neutral                2025-04-09 11:11:30+00:00   \n",
       "196           0.0000   Neutral                2025-04-09 11:11:27+00:00   \n",
       "197          -0.5423  Negative                2025-04-09 11:11:27+00:00   \n",
       "198           0.0000   Neutral                2025-04-09 11:11:26+00:00   \n",
       "199           0.0000   Neutral                2025-04-09 11:11:25+00:00   \n",
       "\n",
       "              Hashtags    Mentions         Username  Profile Image  \\\n",
       "0                                        Oscar68686  Not Available   \n",
       "1                                        RcSamsung1  Not Available   \n",
       "2                                         PuDdInG5_  Not Available   \n",
       "3                                        kenji_yogi  Not Available   \n",
       "4                                      calonkamumas  Not Available   \n",
       "..                 ...         ...              ...            ...   \n",
       "195  #telegraafpremium  @Telegraaf      johan1970nl  Not Available   \n",
       "196                                            f1at  Not Available   \n",
       "197                                        Nellteg1  Not Available   \n",
       "198                                 kemo3asada51345  Not Available   \n",
       "199                                       quellspfc  Not Available   \n",
       "\n",
       "                                                 Media   Device  \\\n",
       "0    https://pbs.twimg.com/profile_images/190779772...  Unknown   \n",
       "1    https://pbs.twimg.com/profile_images/190629084...  Unknown   \n",
       "2    https://pbs.twimg.com/profile_images/190683589...  Unknown   \n",
       "3    https://pbs.twimg.com/profile_images/166714932...  Unknown   \n",
       "4    https://pbs.twimg.com/profile_images/176090691...  Unknown   \n",
       "..                                                 ...      ...   \n",
       "195  https://pbs.twimg.com/profile_images/650051636...  Unknown   \n",
       "196  https://pbs.twimg.com/profile_images/755025300...  Unknown   \n",
       "197  https://pbs.twimg.com/profile_images/185375689...  Unknown   \n",
       "198  https://abs.twimg.com/sticky/default_profile_i...  Unknown   \n",
       "199  https://pbs.twimg.com/profile_images/190813881...  Unknown   \n",
       "\n",
       "                          Location        Date  \n",
       "0    Hérault, Languedoc-Roussillon  2025-04-09  \n",
       "1                          Unknown  2025-04-09  \n",
       "2                               21  2025-04-09  \n",
       "3           St john's co-cathedral  2025-04-09  \n",
       "4                         di rumah  2025-04-09  \n",
       "..                             ...         ...  \n",
       "195               Breda, Nederland  2025-04-09  \n",
       "196                        Unknown  2025-04-09  \n",
       "197                        Unknown  2025-04-09  \n",
       "198                        Unknown  2025-04-09  \n",
       "199                        Unknown  2025-04-09  \n",
       "\n",
       "[200 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f8183bf-848f-4bbe-8dcf-5aa90218d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65c98386-e6ec-4078-9f5b-2bd744e75e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scraping Complete! 200 tweets saved to multi_brand_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "# **Save to CSV**\n",
    "df.to_csv(\"multi_brand_info.csv\", index=False)\n",
    "print(f\"✅ Scraping Complete! {len(df)} tweets saved to multi_brand_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e018128-773d-46a8-bee9-0cba5078d44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data cleaned & saved as cleaned_multi_brand_info.csv (All 200 tweets kept)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "# Load scraped data\n",
    "df = pd.read_csv(\"multi_brand_info.csv\")\n",
    "\n",
    "# Remove empty tweets\n",
    "df = df[df[\"Tweet\"] != \"Not Found\"]\n",
    "\n",
    "# Convert numeric columns\n",
    "df[\"Likes\"] = pd.to_numeric(df[\"Likes\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"Retweets\"] = pd.to_numeric(df[\"Retweets\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Safe language detection\n",
    "def safe_detect(text):\n",
    "    try:\n",
    "        return detect(text) if text and text != \"Not Found\" else \"unknown\"\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "df[\"Language\"] = df[\"Tweet\"].apply(safe_detect)\n",
    "\n",
    "# Categorize sentiment (only for English, else Neutral)\n",
    "def categorize_sentiment(score, lang):\n",
    "    if lang != \"en\":\n",
    "        return \"Neutral\"\n",
    "    if score > 0:\n",
    "        return \"Positive\"\n",
    "    elif score < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df[\"Sentiment\"] = df.apply(lambda row: categorize_sentiment(row[\"Sentiment Score\"], row[\"Language\"]), axis=1)\n",
    "\n",
    "# Add engagement metric\n",
    "df[\"Engagement\"] = df[\"Likes\"] + df[\"Retweets\"]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['Device'])\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(\"cleaned_multi_brand_info.csv\", index=False)\n",
    "print(\"✅ Data cleaned & saved as cleaned_multi_brand_info.csv (All 200 tweets kept)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5ed671-82ea-427c-aa6a-97e42ed132ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Brand column cleaned & saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"cleaned_multi_brand_info.csv\")\n",
    "\n",
    "# Clean Brand column\n",
    "df['Brand'] = df['Brand'].str.strip().str.title()  # removes whitespace and capitalizes\n",
    "\n",
    "# Optional: filter to only Samsung and iPhone if there are other brands\n",
    "df = df[df['Brand'].isin(['Samsung', 'Iphone'])]\n",
    "\n",
    "df.to_csv(\"cleaned_multi_brand_info.csv\", index=False)\n",
    "print(\"✅ Brand column cleaned & saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5e31e4-eb1c-4dd3-b9e0-6ba865924f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Word frequency by brand saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Load your cleaned data\n",
    "df = pd.read_csv(\"cleaned_multi_brand_info.csv\")\n",
    "\n",
    "# Define stopwords\n",
    "stopwords = set([\n",
    "    \"the\", \"and\", \"for\", \"with\", \"that\", \"this\", \"you\", \"your\", \"are\", \"have\",\n",
    "    \"has\", \"they\", \"their\", \"from\", \"what\", \"get\", \"out\", \"now\", \"its\", \"it's\",\n",
    "    \"how\", \"more\", \"just\", \"was\", \"our\", \"about\", \"all\"\n",
    "])\n",
    "\n",
    "# Create word frequency list with brand\n",
    "rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    brand = row[\"Brand\"]\n",
    "    tweet = str(row[\"Tweet\"]).lower()\n",
    "    tweet = re.sub(r\"http\\S+|@\\S+|#\\S+|[^a-zA-Z\\s]\", \"\", tweet)  # Remove links, tags, etc.\n",
    "    words = tweet.split()\n",
    "    filtered = [w for w in words if len(w) > 2 and w not in stopwords]\n",
    "    for word in filtered:\n",
    "        rows.append((brand, word))\n",
    "\n",
    "word_df = pd.DataFrame(rows, columns=[\"Brand\", \"Word\"])\n",
    "word_freq = word_df.groupby([\"Brand\", \"Word\"]).size().reset_index(name=\"Frequency\")\n",
    "\n",
    "# Save it\n",
    "word_freq.to_excel(\"tweet_word_freq_by_brand.xlsx\", index=False)\n",
    "print(\"✅ Word frequency by brand saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
