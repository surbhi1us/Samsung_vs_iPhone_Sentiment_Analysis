{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b079047-0056-49e2-a31f-db68c1144c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Surbhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import random\n",
    "\n",
    "# Initialize Sentiment Analyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "driver = webdriver.Edge()  \n",
    "driver.get(\"https://x.com/login\")  # Open Twitter login page\n",
    "time.sleep(5)  # Wait for page to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b38eaf-333b-472f-89ad-15e1c752eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()  # Load .env variables\n",
    "\n",
    "username = os.getenv(\"TWITTER_USERNAME\")\n",
    "password = os.getenv(\"TWITTER_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc503101-199c-46a1-90cb-1a1154da4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter username\n",
    "username_input = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//input[@name=\"text\"]'))\n",
    ")\n",
    "username_input.send_keys(username)\n",
    "username_input.send_keys(Keys.RETURN)\n",
    "time.sleep(3)\n",
    "\n",
    "# Wait and enter password\n",
    "password_input = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//input[@name=\"password\"]'))\n",
    ")\n",
    "password_input.send_keys(password)\n",
    "password_input.send_keys(Keys.RETURN)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16db9989-dafe-4c56-80b1-7532b3c06e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Searching for tweets about Samsung...\n",
      "üìù 19 tweets loaded for Samsung...\n",
      "üìù 32 tweets loaded for Samsung...\n",
      "üìù 49 tweets loaded for Samsung...\n",
      "üìù 59 tweets loaded for Samsung...\n",
      "üìù 77 tweets loaded for Samsung...\n",
      "üìù 90 tweets loaded for Samsung...\n",
      "üìù 100 tweets loaded for Samsung...\n",
      "üîÑ Searching for tweets about iPhone...\n",
      "üìù 13 tweets loaded for iPhone...\n",
      "üìù 27 tweets loaded for iPhone...\n",
      "üìù 36 tweets loaded for iPhone...\n",
      "üìù 47 tweets loaded for iPhone...\n",
      "üìù 55 tweets loaded for iPhone...\n",
      "üìù 67 tweets loaded for iPhone...\n",
      "üìù 79 tweets loaded for iPhone...\n",
      "üìù 89 tweets loaded for iPhone...\n",
      "üìù 100 tweets loaded for iPhone...\n"
     ]
    }
   ],
   "source": [
    "# Helper: Extract location by visiting profile\n",
    "def get_user_location(username):\n",
    "    try:\n",
    "        profile_url = f\"https://x.com/{username}\"\n",
    "        driver.execute_script(\"window.open('');\")\n",
    "        driver.switch_to.window(driver.window_handles[1])\n",
    "        driver.get(profile_url)\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "\n",
    "        # Try getting location by scanning the profile's bio section\n",
    "        spans = driver.find_elements(By.XPATH, '//div[@data-testid=\"UserProfileHeader_Items\"]/span')\n",
    "        for span in spans:\n",
    "            txt = span.text.strip()\n",
    "            if txt and not txt.startswith(\"@\") and not txt.startswith(\"Joined\"):\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                return txt\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        return \"Unknown\"\n",
    "    except:\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Setup\n",
    "brands = [\"Samsung\", \"iPhone\"]\n",
    "all_tweets = []\n",
    "TWEETS_PER_BRAND = 100  # Reduce for testing, can increase\n",
    "all_hashtags = []\n",
    "all_keywords = []\n",
    "visited_users = {}\n",
    "\n",
    "for brand in brands:\n",
    "    print(f\"üîÑ Searching for tweets about {brand}...\")\n",
    "\n",
    "    search_url = f\"https://x.com/search?q={brand}&src=typed_query&f=live\"\n",
    "    driver.get(search_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    tweet_data = []\n",
    "    scroll_attempts = 0\n",
    "    max_scrolls = 30\n",
    "\n",
    "    while len(tweet_data) < TWEETS_PER_BRAND and scroll_attempts < max_scrolls:\n",
    "        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "\n",
    "        tweets = driver.find_elements(By.XPATH, '//article[@data-testid=\"tweet\"]')\n",
    "\n",
    "        for tweet in tweets:\n",
    "            if len(tweet_data) >= TWEETS_PER_BRAND:\n",
    "                break\n",
    "\n",
    "            tweet_info = {\"Brand\": brand}\n",
    "\n",
    "            try:\n",
    "                tweet_text = tweet.find_element(By.XPATH, './/div[@data-testid=\"tweetText\"]').text\n",
    "                tweet_info[\"Tweet\"] = tweet_text\n",
    "            except:\n",
    "                tweet_info[\"Tweet\"] = \"Not Found\"\n",
    "\n",
    "            tweet_info[\"Sentiment Score\"] = sia.polarity_scores(tweet_info[\"Tweet\"])[\"compound\"]\n",
    "            tweet_info[\"Sentiment\"] = (\n",
    "                \"Positive\" if tweet_info[\"Sentiment Score\"] > 0\n",
    "                else \"Negative\" if tweet_info[\"Sentiment Score\"] < 0\n",
    "                else \"Neutral\"\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                likes = tweet.find_element(By.XPATH, './/button[@data-testid=\"like\"]//span').text\n",
    "                tweet_info[\"Likes\"] = likes.replace(\"K\", \"000\").replace(\"M\", \"000000\")\n",
    "            except:\n",
    "                tweet_info[\"Likes\"] = \"0\"\n",
    "\n",
    "            try:\n",
    "                retweets = tweet.find_element(By.XPATH, './/button[@data-testid=\"retweet\"]//span').text\n",
    "                tweet_info[\"Retweets\"] = retweets.replace(\"K\", \"000\").replace(\"M\", \"000000\")\n",
    "            except:\n",
    "                tweet_info[\"Retweets\"] = \"0\"\n",
    "\n",
    "            try:\n",
    "                tweet_info[\"Time\"] = tweet.find_element(By.XPATH, './/time').get_attribute(\"datetime\")\n",
    "            except:\n",
    "                tweet_info[\"Time\"] = \"Not Available\"\n",
    "\n",
    "            hashtags = [word for word in tweet_info[\"Tweet\"].split() if word.startswith(\"#\")]\n",
    "            mentions = [word for word in tweet_info[\"Tweet\"].split() if word.startswith(\"@\")]\n",
    "            tweet_info[\"Hashtags\"] = \", \".join(hashtags)\n",
    "            tweet_info[\"Mentions\"] = \", \".join(mentions)\n",
    "            all_hashtags.extend(hashtags)\n",
    "            all_keywords.extend(tweet_info[\"Tweet\"].split())\n",
    "\n",
    "            try:\n",
    "                handle_elem = tweet.find_element(By.XPATH, './/a[contains(@href, \"/status/\")]')\n",
    "                handle_url = handle_elem.get_attribute(\"href\")\n",
    "                username = handle_url.split(\"/\")[3]  # https://x.com/{username}/status/...\n",
    "                tweet_info[\"Username\"] = username\n",
    "            except:\n",
    "                tweet_info[\"Username\"] = \"Unknown\"\n",
    "                username = \"Unknown\"\n",
    "\n",
    "            try:\n",
    "                img = tweet.find_element(By.XPATH, './/img[contains(@alt, \"Image\")]')\n",
    "                tweet_info[\"Profile Image\"] = img.get_attribute(\"src\")\n",
    "            except:\n",
    "                tweet_info[\"Profile Image\"] = \"Not Available\"\n",
    "\n",
    "            try:\n",
    "                media = tweet.find_element(By.XPATH, './/img[contains(@src, \"twimg\")]')\n",
    "                tweet_info[\"Media\"] = media.get_attribute(\"src\")\n",
    "            except:\n",
    "                tweet_info[\"Media\"] = \"None\"\n",
    "\n",
    "            try:\n",
    "                device_element = tweet.find_elements(By.XPATH, './/span[contains(@class, \"css-901oao\")]')\n",
    "                for el in device_element:\n",
    "                    text = el.text\n",
    "                    if \"Twitter for\" in text:\n",
    "                        tweet_info[\"Device\"] = text\n",
    "                        break\n",
    "                else:\n",
    "                    tweet_info[\"Device\"] = \"Unknown\"\n",
    "            except:\n",
    "                tweet_info[\"Device\"] = \"Unknown\"\n",
    "\n",
    "            # Get location from profile only if username is known\n",
    "            if username != \"Unknown\":\n",
    "                if username in visited_users:\n",
    "                    tweet_info[\"Location\"] = visited_users[username]\n",
    "                else:\n",
    "                    loc = get_user_location(username)\n",
    "                    visited_users[username] = loc\n",
    "                    tweet_info[\"Location\"] = loc\n",
    "            else:\n",
    "                tweet_info[\"Location\"] = \"Unknown\"\n",
    "\n",
    "            tweet_data.append(tweet_info)\n",
    "\n",
    "        print(f\"üìù {len(tweet_data)} tweets loaded for {brand}...\")\n",
    "        scroll_attempts += 1\n",
    "\n",
    "    all_tweets.extend(tweet_data)\n",
    "\n",
    "# Save data\n",
    "df = pd.DataFrame(all_tweets)\n",
    "df['Time'] = pd.to_datetime(df['Time'], errors='coerce')\n",
    "df['Date'] = df['Time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cc241c1-6f3b-43ce-a9aa-15977a18cf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Time</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Username</th>\n",
       "      <th>Profile Image</th>\n",
       "      <th>Media</th>\n",
       "      <th>Device</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Je m'en fous des iPhones j'ai toujours eu des ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:07:54+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Oscar68686</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/190779772...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>H√©rault, Languedoc-Roussillon</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Mlm ini juga aku jabanin,</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>Negative</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:07:53+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RcSamsung1</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/190629084...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>ÏßÑÎßåÎàÑÎÇò ÎØøÏñ¥Ïöî</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:07:52+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>PuDdInG5_</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/190683589...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Samsung„ÅÆ„É™„É≥„Ç∞„ÇÇË¶ã„Å¶„Åø„Åü„Çâ5„Äú15Âè∑\\nË™∞„ÅÆ„Å©„ÅÆÊåá„Å´‰ªò„Åë„Çã„Åì„Å®ÂâçÊèê„Å™„Çì„Å†„Çç„ÅÜÔºüÂ§ß‰∫∫„Åå...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:07:48+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kenji_yogi</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/166714932...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>St john's co-cathedral</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>Aku pengguna samsung dari tahun 2018, hp perta...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:07:41+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>calonkamumas</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/176090691...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>di rumah</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>iPhone dreigt onbetaalbaar te worden door Trum...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:11:30+00:00</td>\n",
       "      <td>#telegraafpremium</td>\n",
       "      <td>@Telegraaf</td>\n",
       "      <td>johan1970nl</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/650051636...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Breda, Nederland</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>„Ç¢„É°„É™„Ç´‰∫∫„ÄÅ„ÇÇ„ÅÜiPhone„Åã„Åà„Çì„Çà„ÅÜ„Å´„Å™„Çã„Å™</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:11:27+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>f1at</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/755025300...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>Oye que c√°mara tan horrible del iPhone 15 pro ...</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>Negative</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:11:27+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Nellteg1</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/185375689...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>‰ªä„ÅÆ„ÅÜ„Å°„Å´iPhoneË≤∑„Å£„Å®„Åã„Å™„ÅÑ„Å®ÂõΩÂÜÖ„ÇÇ‰∏≠Âè§ÂìÅÊö¥È®∞„Åô„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„ÅÆ\\nËª¢Â£≤„É§„ÉºÊ≠ìÂñú„Åó„Å¶„Åù„ÅÜ</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:11:26+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>kemo3asada51345</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://abs.twimg.com/sticky/default_profile_i...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>s√≥ fala mal de iphone quem n√£o tem</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-04-09 11:11:25+00:00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>quellspfc</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/190813881...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2025-04-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                              Tweet  \\\n",
       "0    Samsung  Je m'en fous des iPhones j'ai toujours eu des ...   \n",
       "1    Samsung                         Mlm ini juga aku jabanin,    \n",
       "2    Samsung                                           ÏßÑÎßåÎàÑÎÇò ÎØøÏñ¥Ïöî   \n",
       "3    Samsung  Samsung„ÅÆ„É™„É≥„Ç∞„ÇÇË¶ã„Å¶„Åø„Åü„Çâ5„Äú15Âè∑\\nË™∞„ÅÆ„Å©„ÅÆÊåá„Å´‰ªò„Åë„Çã„Åì„Å®ÂâçÊèê„Å™„Çì„Å†„Çç„ÅÜÔºüÂ§ß‰∫∫„Åå...   \n",
       "4    Samsung  Aku pengguna samsung dari tahun 2018, hp perta...   \n",
       "..       ...                                                ...   \n",
       "195   iPhone  iPhone dreigt onbetaalbaar te worden door Trum...   \n",
       "196   iPhone                            „Ç¢„É°„É™„Ç´‰∫∫„ÄÅ„ÇÇ„ÅÜiPhone„Åã„Åà„Çì„Çà„ÅÜ„Å´„Å™„Çã„Å™   \n",
       "197   iPhone  Oye que c√°mara tan horrible del iPhone 15 pro ...   \n",
       "198   iPhone     ‰ªä„ÅÆ„ÅÜ„Å°„Å´iPhoneË≤∑„Å£„Å®„Åã„Å™„ÅÑ„Å®ÂõΩÂÜÖ„ÇÇ‰∏≠Âè§ÂìÅÊö¥È®∞„Åô„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„ÅÆ\\nËª¢Â£≤„É§„ÉºÊ≠ìÂñú„Åó„Å¶„Åù„ÅÜ   \n",
       "199   iPhone                 s√≥ fala mal de iphone quem n√£o tem   \n",
       "\n",
       "     Sentiment Score Sentiment Likes Retweets                      Time  \\\n",
       "0             0.0000   Neutral                2025-04-09 11:07:54+00:00   \n",
       "1            -0.3400  Negative                2025-04-09 11:07:53+00:00   \n",
       "2             0.0000   Neutral                2025-04-09 11:07:52+00:00   \n",
       "3             0.0000   Neutral                2025-04-09 11:07:48+00:00   \n",
       "4             0.0000   Neutral                2025-04-09 11:07:41+00:00   \n",
       "..               ...       ...   ...      ...                       ...   \n",
       "195           0.0000   Neutral                2025-04-09 11:11:30+00:00   \n",
       "196           0.0000   Neutral                2025-04-09 11:11:27+00:00   \n",
       "197          -0.5423  Negative                2025-04-09 11:11:27+00:00   \n",
       "198           0.0000   Neutral                2025-04-09 11:11:26+00:00   \n",
       "199           0.0000   Neutral                2025-04-09 11:11:25+00:00   \n",
       "\n",
       "              Hashtags    Mentions         Username  Profile Image  \\\n",
       "0                                        Oscar68686  Not Available   \n",
       "1                                        RcSamsung1  Not Available   \n",
       "2                                         PuDdInG5_  Not Available   \n",
       "3                                        kenji_yogi  Not Available   \n",
       "4                                      calonkamumas  Not Available   \n",
       "..                 ...         ...              ...            ...   \n",
       "195  #telegraafpremium  @Telegraaf      johan1970nl  Not Available   \n",
       "196                                            f1at  Not Available   \n",
       "197                                        Nellteg1  Not Available   \n",
       "198                                 kemo3asada51345  Not Available   \n",
       "199                                       quellspfc  Not Available   \n",
       "\n",
       "                                                 Media   Device  \\\n",
       "0    https://pbs.twimg.com/profile_images/190779772...  Unknown   \n",
       "1    https://pbs.twimg.com/profile_images/190629084...  Unknown   \n",
       "2    https://pbs.twimg.com/profile_images/190683589...  Unknown   \n",
       "3    https://pbs.twimg.com/profile_images/166714932...  Unknown   \n",
       "4    https://pbs.twimg.com/profile_images/176090691...  Unknown   \n",
       "..                                                 ...      ...   \n",
       "195  https://pbs.twimg.com/profile_images/650051636...  Unknown   \n",
       "196  https://pbs.twimg.com/profile_images/755025300...  Unknown   \n",
       "197  https://pbs.twimg.com/profile_images/185375689...  Unknown   \n",
       "198  https://abs.twimg.com/sticky/default_profile_i...  Unknown   \n",
       "199  https://pbs.twimg.com/profile_images/190813881...  Unknown   \n",
       "\n",
       "                          Location        Date  \n",
       "0    H√©rault, Languedoc-Roussillon  2025-04-09  \n",
       "1                          Unknown  2025-04-09  \n",
       "2                               21  2025-04-09  \n",
       "3           St john's co-cathedral  2025-04-09  \n",
       "4                         di rumah  2025-04-09  \n",
       "..                             ...         ...  \n",
       "195               Breda, Nederland  2025-04-09  \n",
       "196                        Unknown  2025-04-09  \n",
       "197                        Unknown  2025-04-09  \n",
       "198                        Unknown  2025-04-09  \n",
       "199                        Unknown  2025-04-09  \n",
       "\n",
       "[200 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f8183bf-848f-4bbe-8dcf-5aa90218d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65c98386-e6ec-4078-9f5b-2bd744e75e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraping Complete! 200 tweets saved to multi_brand_tweets.csv\n"
     ]
    }
   ],
   "source": [
    "# **Save to CSV**\n",
    "df.to_csv(\"multi_brand_info.csv\", index=False)\n",
    "print(f\"‚úÖ Scraping Complete! {len(df)} tweets saved to multi_brand_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e018128-773d-46a8-bee9-0cba5078d44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data cleaned & saved as cleaned_multi_brand_info.csv (All 200 tweets kept)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "# Load scraped data\n",
    "df = pd.read_csv(\"multi_brand_info.csv\")\n",
    "\n",
    "# Remove empty tweets\n",
    "df = df[df[\"Tweet\"] != \"Not Found\"]\n",
    "\n",
    "# Convert numeric columns\n",
    "df[\"Likes\"] = pd.to_numeric(df[\"Likes\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"Retweets\"] = pd.to_numeric(df[\"Retweets\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Safe language detection\n",
    "def safe_detect(text):\n",
    "    try:\n",
    "        return detect(text) if text and text != \"Not Found\" else \"unknown\"\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "df[\"Language\"] = df[\"Tweet\"].apply(safe_detect)\n",
    "\n",
    "# Categorize sentiment (only for English, else Neutral)\n",
    "def categorize_sentiment(score, lang):\n",
    "    if lang != \"en\":\n",
    "        return \"Neutral\"\n",
    "    if score > 0:\n",
    "        return \"Positive\"\n",
    "    elif score < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df[\"Sentiment\"] = df.apply(lambda row: categorize_sentiment(row[\"Sentiment Score\"], row[\"Language\"]), axis=1)\n",
    "\n",
    "# Add engagement metric\n",
    "df[\"Engagement\"] = df[\"Likes\"] + df[\"Retweets\"]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['Device'])\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(\"cleaned_multi_brand_info.csv\", index=False)\n",
    "print(\"‚úÖ Data cleaned & saved as cleaned_multi_brand_info.csv (All 200 tweets kept)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5ed671-82ea-427c-aa6a-97e42ed132ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Brand column cleaned & saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"cleaned_multi_brand_info.csv\")\n",
    "\n",
    "# Clean Brand column\n",
    "df['Brand'] = df['Brand'].str.strip().str.title()  # removes whitespace and capitalizes\n",
    "\n",
    "# Optional: filter to only Samsung and iPhone if there are other brands\n",
    "df = df[df['Brand'].isin(['Samsung', 'Iphone'])]\n",
    "\n",
    "df.to_csv(\"cleaned_multi_brand_info.csv\", index=False)\n",
    "print(\"‚úÖ Brand column cleaned & saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5e31e4-eb1c-4dd3-b9e0-6ba865924f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Word frequency by brand saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Load your cleaned data\n",
    "df = pd.read_csv(\"cleaned_multi_brand_info.csv\")\n",
    "\n",
    "# Define stopwords\n",
    "stopwords = set([\n",
    "    \"the\", \"and\", \"for\", \"with\", \"that\", \"this\", \"you\", \"your\", \"are\", \"have\",\n",
    "    \"has\", \"they\", \"their\", \"from\", \"what\", \"get\", \"out\", \"now\", \"its\", \"it's\",\n",
    "    \"how\", \"more\", \"just\", \"was\", \"our\", \"about\", \"all\"\n",
    "])\n",
    "\n",
    "# Create word frequency list with brand\n",
    "rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    brand = row[\"Brand\"]\n",
    "    tweet = str(row[\"Tweet\"]).lower()\n",
    "    tweet = re.sub(r\"http\\S+|@\\S+|#\\S+|[^a-zA-Z\\s]\", \"\", tweet)  # Remove links, tags, etc.\n",
    "    words = tweet.split()\n",
    "    filtered = [w for w in words if len(w) > 2 and w not in stopwords]\n",
    "    for word in filtered:\n",
    "        rows.append((brand, word))\n",
    "\n",
    "word_df = pd.DataFrame(rows, columns=[\"Brand\", \"Word\"])\n",
    "word_freq = word_df.groupby([\"Brand\", \"Word\"]).size().reset_index(name=\"Frequency\")\n",
    "\n",
    "# Save it\n",
    "word_freq.to_excel(\"tweet_word_freq_by_brand.xlsx\", index=False)\n",
    "print(\"‚úÖ Word frequency by brand saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
